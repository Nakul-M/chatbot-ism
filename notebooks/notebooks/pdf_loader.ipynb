{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "793170e1",
   "metadata": {},
   "source": [
    "## DATA INGESTION TO VECTOR DB PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02c1eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rag/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db7d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 PDF files to process\n",
      "\n",
      "Processing: data1.pdf\n",
      "  ✓ Loaded 60 pages\n",
      "\n",
      "Total documents loaded: 60\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")\n",
    "\n",
    "\n",
    "##.  each page have a document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4553592",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=100,chunk_overlap=20):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace6aa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 60 documents into 1100 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Section 1: Introduction and Overview...\n",
      "Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-10-13T08:33:41+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-10-13T08:33:41+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '../data/pdf/data1.pdf', 'total_pages': 60, 'page': 0, 'page_label': '1', 'source_file': 'data1.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks =split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54704c9b",
   "metadata": {},
   "source": [
    "## EXECUTING AND vectorstoreDB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f14cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb. config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics. pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5811c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x165db9fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc69c1",
   "metadata": {},
   "source": [
    "##  embedding model is ready \n",
    "\n",
    "## just need to use it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ee96d",
   "metadata": {},
   "source": [
    "# vector store db for storing the vector in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2615f879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x165dba270>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store (save in db )\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name, ## where to store in the vectordb\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b5fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1100 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 35/35 [00:04<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1100, 384)\n",
      "Adding 1100 documents to vector store...\n",
      "Successfully added 1100 documents to vector store\n",
      "Total documents in collection: 1100\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts) ## list of strings\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d1621",
   "metadata": {},
   "source": [
    " # RAG RETRIEVER FROM THE VECTORSTORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896df6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "     \n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a152fa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x1671cc830>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62fa314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_9aea7f50_692',\n",
       "  'content': 'Section 7: Student Features',\n",
       "  'metadata': {'creationdate': '2025-10-13T08:33:41+00:00',\n",
       "   'creator': '(unspecified)',\n",
       "   'title': '(anonymous)',\n",
       "   'total_pages': 60,\n",
       "   'subject': '(unspecified)',\n",
       "   'page_label': '39',\n",
       "   'moddate': '2025-10-13T08:33:41+00:00',\n",
       "   'source': '../data/pdf/data1.pdf',\n",
       "   'trapped': '/False',\n",
       "   'content_length': 27,\n",
       "   'keywords': '',\n",
       "   'page': 38,\n",
       "   'file_type': 'pdf',\n",
       "   'producer': 'ReportLab PDF Library - www.reportlab.com',\n",
       "   'source_file': 'data1.pdf',\n",
       "   'author': '(anonymous)',\n",
       "   'doc_index': 692},\n",
       "  'similarity_score': 0.16122019290924072,\n",
       "  'distance': 0.8387798070907593,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_5fe1ce55_1022',\n",
       "  'content': 'Section 10: Student Features',\n",
       "  'metadata': {'subject': '(unspecified)',\n",
       "   'moddate': '2025-10-13T08:33:41+00:00',\n",
       "   'content_length': 28,\n",
       "   'page_label': '57',\n",
       "   'keywords': '',\n",
       "   'file_type': 'pdf',\n",
       "   'producer': 'ReportLab PDF Library - www.reportlab.com',\n",
       "   'trapped': '/False',\n",
       "   'source': '../data/pdf/data1.pdf',\n",
       "   'title': '(anonymous)',\n",
       "   'page': 56,\n",
       "   'total_pages': 60,\n",
       "   'author': '(anonymous)',\n",
       "   'doc_index': 1022,\n",
       "   'creationdate': '2025-10-13T08:33:41+00:00',\n",
       "   'creator': '(unspecified)',\n",
       "   'source_file': 'data1.pdf'},\n",
       "  'similarity_score': 0.1497814655303955,\n",
       "  'distance': 0.8502185344696045,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_ae1e2bc3_252',\n",
       "  'content': 'Section 3: Student Features',\n",
       "  'metadata': {'author': '(anonymous)',\n",
       "   'source': '../data/pdf/data1.pdf',\n",
       "   'total_pages': 60,\n",
       "   'creator': '(unspecified)',\n",
       "   'creationdate': '2025-10-13T08:33:41+00:00',\n",
       "   'page_label': '15',\n",
       "   'keywords': '',\n",
       "   'title': '(anonymous)',\n",
       "   'doc_index': 252,\n",
       "   'page': 14,\n",
       "   'moddate': '2025-10-13T08:33:41+00:00',\n",
       "   'trapped': '/False',\n",
       "   'file_type': 'pdf',\n",
       "   'content_length': 27,\n",
       "   'source_file': 'data1.pdf',\n",
       "   'subject': '(unspecified)',\n",
       "   'producer': 'ReportLab PDF Library - www.reportlab.com'},\n",
       "  'similarity_score': 0.14841943979263306,\n",
       "  'distance': 0.8515805602073669,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_8c13c6ed_32',\n",
       "  'content': 'Section 1: Student Features',\n",
       "  'metadata': {'file_type': 'pdf',\n",
       "   'creator': '(unspecified)',\n",
       "   'doc_index': 32,\n",
       "   'creationdate': '2025-10-13T08:33:41+00:00',\n",
       "   'producer': 'ReportLab PDF Library - www.reportlab.com',\n",
       "   'author': '(anonymous)',\n",
       "   'content_length': 27,\n",
       "   'keywords': '',\n",
       "   'source': '../data/pdf/data1.pdf',\n",
       "   'source_file': 'data1.pdf',\n",
       "   'trapped': '/False',\n",
       "   'total_pages': 60,\n",
       "   'subject': '(unspecified)',\n",
       "   'page_label': '3',\n",
       "   'title': '(anonymous)',\n",
       "   'page': 2,\n",
       "   'moddate': '2025-10-13T08:33:41+00:00'},\n",
       "  'similarity_score': 0.14705705642700195,\n",
       "  'distance': 0.852942943572998,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_77563dfe_472',\n",
       "  'content': 'Section 5: Student Features',\n",
       "  'metadata': {'producer': 'ReportLab PDF Library - www.reportlab.com',\n",
       "   'page_label': '27',\n",
       "   'title': '(anonymous)',\n",
       "   'creator': '(unspecified)',\n",
       "   'doc_index': 472,\n",
       "   'source': '../data/pdf/data1.pdf',\n",
       "   'trapped': '/False',\n",
       "   'total_pages': 60,\n",
       "   'author': '(anonymous)',\n",
       "   'creationdate': '2025-10-13T08:33:41+00:00',\n",
       "   'page': 26,\n",
       "   'content_length': 27,\n",
       "   'keywords': '',\n",
       "   'subject': '(unspecified)',\n",
       "   'moddate': '2025-10-13T08:33:41+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'source_file': 'data1.pdf'},\n",
       "  'similarity_score': 0.1456143856048584,\n",
       "  'distance': 0.8543856143951416,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"student\") ## we will get a context now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155bbe08",
   "metadata": {},
   "source": [
    "## LLM integration. with the context pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ed311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq LLM\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "def rag_portal_assistant(user_query, retriever, llm, top_k=5):\n",
    "    \"\"\"\n",
    "    RAG pipeline for Student Management Portal chatbot.\n",
    "    Retrieves relevant content from the portal guide and generates a contextual answer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Retrieve top-k relevant guide chunks\n",
    "    guide_results = retriever.retrieve(user_query, top_k=top_k)\n",
    "    guide_context = \"\\n\\n\".join([doc['content'] for doc in guide_results]) if guide_results else \"\"\n",
    "\n",
    "    if not guide_context:\n",
    "        return \"Sorry, I couldn’t find relevant information in the guide for your query.\"\n",
    "\n",
    "    # Step 2: Construct contextual prompt\n",
    "    prompt = f\"\"\"\n",
    "You are a **Student Management Portal assistant** helping teachers and students.\n",
    "Answer queries strictly based on the following guide context.\n",
    "\n",
    "---\n",
    "### 📘 Portal Guide Context:\n",
    "{guide_context}\n",
    "\n",
    "---\n",
    "### 💬 User Query:\n",
    "{user_query}\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Instructions:\n",
    "- Answer clearly and politely.\n",
    "- If the question is related to portal usage, explain the exact steps.\n",
    "- If it’s about academic or administrative policy, summarize the rule.\n",
    "- If information is not in the guide, respond: *\"This detail is not mentioned in the portal guide.\"*\n",
    "- Avoid assumptions — stay factual.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Response (Markdown Format):\n",
    "\n",
    "**Answer:**\n",
    "- ...\n",
    "\n",
    "**Related Module:**\n",
    "- ...\n",
    "\n",
    "**Tip (if applicable):**\n",
    "- ...\n",
    "\"\"\"\n",
    "\n",
    "    # Step 3: Generate response\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d0be33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n",
      "**Answer:**\n",
      "You can view exam schedules, grades, and performance analytics within the 'Exams and Results' module of the portal.\n",
      "\n",
      "**Related Module:**\n",
      "Exams and Results\n",
      "\n",
      "**Tip (if applicable):**\n",
      "To access the 'Exams and Results' module, please follow these steps:\n",
      "1. Log in to the portal.\n",
      "2. Click on the 'Exams and Results' tab on the top navigation menu.\n",
      "3. Select the relevant exam schedule, grade, or performance analytics from the available options.\n"
     ]
    }
   ],
   "source": [
    "query = \"Exam\"\n",
    "answer = rag_portal_assistant(query, rag_retriever, llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1906a3",
   "metadata": {},
   "source": [
    "# ENHANCED RAG PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ebfb625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Exam schedules, grades, and performance analytics are available within the 'Exams and Results'.\n",
      "Sources: [{'source': 'data1.pdf', 'page': 26, 'score': 0.3047114610671997, 'preview': \"Exam schedules, grades, and performance analytics are available within the 'Exams and Results'...\"}, {'source': 'data1.pdf', 'page': 38, 'score': 0.3047114610671997, 'preview': \"Exam schedules, grades, and performance analytics are available within the 'Exams and Results'...\"}, {'source': 'data1.pdf', 'page': 56, 'score': 0.3047114610671997, 'preview': \"Exam schedules, grades, and performance analytics are available within the 'Exams and Results'...\"}]\n",
      "Confidence: 0.3047114610671997\n",
      "Context Preview: Exam schedules, grades, and performance analytics are available within the 'Exams and Results'\n",
      "\n",
      "Exam schedules, grades, and performance analytics are available within the 'Exams and Results'\n",
      "\n",
      "Exam schedules, grades, and performance analytics are available within the 'Exams and Results'\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"Exams query\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abd2d4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Streaming answer:\n",
      "Use the following context to answer the question concisely.\n",
      "Context:\n",
      "Exam schedules, grades, and performance analytics are available within the 'Exams and Resul"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts'\n",
      "\n",
      "Exam schedules, grades, and performance analytics are available within the 'Exams and Results'\n",
      "\n",
      "Exam schedules, grades, and performance analytics are available within the 'Exams and Results'\n",
      "\n",
      "Question: Exams\n",
      "\n",
      "Answer:\n",
      "\n",
      "Final Answer: Exams and Results\n",
      "\n",
      "Citations:\n",
      "[1] data1.pdf (page 8)\n",
      "[2] data1.pdf (page 20)\n",
      "[3] data1.pdf (page 56)\n",
      "Summary: However, you haven't provided an answer for me to summarize. Please provide the text you would like me to summarize, and I'll be happy to assist you.\n",
      "History: {'question': 'Exams', 'answer': 'Exams and Results', 'sources': [{'source': 'data1.pdf', 'page': 8, 'score': 0.2397938370704651, 'preview': \"Exam schedules, grades, and performance analytics are available within the 'Exams and Results'...\"}, {'source': 'data1.pdf', 'page': 20, 'score': 0.2397938370704651, 'preview': \"Exam schedules, grades, and performance analytics are available within the 'Exams and Results'...\"}, {'source': 'data1.pdf', 'page': 56, 'score': 0.2397938370704651, 'preview': \"Exam schedules, grades, and performance analytics are available within the 'Exams and Results'...\"}], 'summary': \"However, you haven't provided an answer for me to summarize. Please provide the text you would like me to summarize, and I'll be happy to assist you.\"}\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"Exams\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0fe17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
